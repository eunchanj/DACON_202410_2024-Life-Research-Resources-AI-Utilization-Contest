{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248037dd-ff7d-445c-a7ce-c41896f81a04",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2752818-38cb-47e4-829b-6b0633c3305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/automl2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/envs/automl2/lib/python3.9/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disable stacking for split validation\n",
      "AutoML directory: AutoML_1\n",
      "The task is multiclass_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Random Forest', 'LightGBM', 'Xgboost', 'CatBoost']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 4 models\n",
      "1_Default_LightGBM logloss 2.498436 trained in 193.38 seconds\n",
      "2_Default_Xgboost logloss 2.319693 trained in 177.9 seconds\n",
      "3_Default_CatBoost logloss 2.276217 trained in 327.24 seconds\n",
      "4_Default_RandomForest logloss 2.535947 trained in 52.97 seconds\n",
      "* Step not_so_random will try to check up to 36 models\n",
      "14_LightGBM logloss 2.457309 trained in 54.65 seconds\n",
      "5_Xgboost logloss 2.459094 trained in 288.46 seconds\n",
      "23_CatBoost logloss 2.269656 trained in 149.65 seconds\n",
      "32_RandomForest logloss 2.539375 trained in 46.2 seconds\n",
      "15_LightGBM logloss 2.534241 trained in 120.4 seconds\n",
      "6_Xgboost logloss 2.342553 trained in 186.2 seconds\n",
      "24_CatBoost logloss 2.268035 trained in 322.83 seconds\n",
      "33_RandomForest logloss 2.401079 trained in 143.94 seconds\n",
      "16_LightGBM logloss 2.537467 trained in 132.11 seconds\n",
      "7_Xgboost logloss 2.491139 trained in 336.98 seconds\n",
      "Skip golden_features because of the time limit.\n",
      "Not enough time to perform features selection. Skip\n",
      "Time needed for features selection ~ 1030.0 seconds\n",
      "Please increase total_time_limit to at least (10357 seconds) to have features selection\n",
      "Skip insert_random_feature because no parameters were generated.\n",
      "Skip features_selection because no parameters were generated.\n",
      "* Step hill_climbing_1 will try to check up to 19 models\n",
      "34_CatBoost logloss 2.248336 trained in 188.57 seconds\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. 데이터 로드 및 전처리\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# 결측값 처리\n",
    "train.fillna('WT', inplace=True)\n",
    "test.fillna('WT', inplace=True)\n",
    "\n",
    "# 변이 열 준비\n",
    "mutation_columns = [col for col in train.columns if col not in ['ID', 'SUBCLASS']]\n",
    "\n",
    "# 변이 정보를 문자열로 결합\n",
    "train['mutations'] = train[mutation_columns].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
    "test['mutations'] = test[mutation_columns].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
    "\n",
    "# 타겟 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "train['SUBCLASS'] = label_encoder.fit_transform(train['SUBCLASS'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# 특징과 타겟 준비\n",
    "X = train['mutations']\n",
    "y = train['SUBCLASS'].astype(int)  # 정수형으로 변환\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(max_features=10000)\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "X_test_tfidf = tfidf.transform(test['mutations'])\n",
    "\n",
    "# 학습 데이터를 훈련 세트와 검증 세트로 분할\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 희소 행렬을 밀집 배열로 변환\n",
    "X_train_dense = X_train.toarray()\n",
    "X_valid_dense = X_valid.toarray()\n",
    "X_test_dense = X_test_tfidf.toarray()\n",
    "\n",
    "# 2. MLJAR AutoML 임포트\n",
    "from supervised.automl import AutoML\n",
    "\n",
    "# 3. AutoML 객체 생성 (Random Forest 알고리즘 추가)\n",
    "automl = AutoML(\n",
    "    mode='Compete',\n",
    "    ml_task='multiclass_classification',  # 작업 유형 명시적으로 지정\n",
    "    total_time_limit=3600,\n",
    "    eval_metric='logloss',\n",
    "    algorithms=['Random Forest', 'LightGBM', 'Xgboost', 'CatBoost'],  # 알고리즘에 Random Forest 추가\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"split\",\n",
    "        \"train_ratio\": 0.8,\n",
    "        \"shuffle\": True,\n",
    "        \"stratify\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "# 4. AutoML 모델 학습\n",
    "automl.fit(X_train_dense, y_train)\n",
    "\n",
    "# 5. 검증 데이터에 대한 예측\n",
    "y_pred = automl.predict(X_valid_dense)\n",
    "\n",
    "# 6. 성능 평가\n",
    "print(\"MLJAR AutoML Classification Report with Random Forest:\")\n",
    "print(classification_report(y_valid, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# 7. 테스트 데이터에 대한 예측\n",
    "y_test_pred = automl.predict(X_test_dense)\n",
    "test['SUBCLASS'] = label_encoder.inverse_transform(y_test_pred.astype(int))\n",
    "\n",
    "# 8. 제출 파일 생성\n",
    "submission = test[['ID', 'SUBCLASS']]\n",
    "submission.to_csv('submission_mljar.csv', index=False)\n",
    "print(\"MLJAR AutoML 제출 파일이 생성되었습니다: submission_mljar.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl2",
   "language": "python",
   "name": "automl2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
